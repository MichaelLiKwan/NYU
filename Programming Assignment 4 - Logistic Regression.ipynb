{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment 4 - Logistic Regression (170 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Important Libraries\n",
    "from sklearn.datasets import load_breast_cancer # taking included data set from Sklearn http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html\n",
    "from sklearn.linear_model import LogisticRegression # importing Sklearn's logistic regression's module\n",
    "from sklearn import preprocessing # preprossing is what we do with the data before we run the learning algorithm\n",
    "from sklearn.model_selection import train_test_split \n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Load the dataset - 5 points\n",
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569,)\n",
      "(569, 30)\n"
     ]
    }
   ],
   "source": [
    "# TODO - Print the shape of data (X) and target (Y) values - 5 points\n",
    "print(cancer.target.shape)\n",
    "print(cancer.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing\n",
    "Scale before splitting the data into train and test- scale the data since we will be using gradient ascent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Use preprocessing to scale the data and use train_test_split to split the data (70% train and 30% test) - 5 points\n",
    "x_scale = preprocessing.scale(cancer.data)\n",
    "y = cancer.target\n",
    "xCutoff = int(len(x_scale)*.75)\n",
    "yCutoff = int(len(y)*.75)\n",
    "x_train, x_test, y_train, y_test = x_scale[:xCutoff], x_scale[xCutoff:], y[:yCutoff], y[yCutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 30)\n",
      "(426,)\n"
     ]
    }
   ],
   "source": [
    "# TODO - Print the shape of x_train and y_train - 5 points\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
     ]
    }
   ],
   "source": [
    "# Printing the names of all the features\n",
    "print(cancer.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Logistic Regression Using Gradient Ascent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Write the sigmoid function - 10 points\n",
    "def sigmoid(z):\n",
    "    return 1/(1+(np.exp(-1*z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "# VERIFY - Sigmoid of 0 should be equal to half\n",
    "print(sigmoid(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 31)\n",
      "[[ 1.          1.09706398 -2.07333501 ...  2.29607613  2.75062224\n",
      "   1.93701461]\n",
      " [ 1.          1.82982061 -0.35363241 ...  1.0870843  -0.24388967\n",
      "   0.28118999]\n",
      " [ 1.          1.57988811  0.45618695 ...  1.95500035  1.152255\n",
      "   0.20139121]\n",
      " ...\n",
      " [ 1.         -0.13271749 -0.03715128 ...  0.39731943 -0.25359635\n",
      "   0.24627802]\n",
      " [ 1.         -1.24548511 -0.03947835 ... -1.04631426  0.47764049\n",
      "  -0.21367326]\n",
      " [ 1.         -1.16368902  0.46316815 ... -1.35236887 -0.89261969\n",
      "  -0.18485704]]\n"
     ]
    }
   ],
   "source": [
    "# TODO - Append a column of ones to x_train - 10 points\n",
    "# ones is a vector of shape n,1\n",
    "ones = np.ones((x_train.shape[0],1))\n",
    "# Append a column of ones in the beginning of x_train an save in variable a.\n",
    "a = np.hstack((ones,x_train))\n",
    "print(a.shape)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 1)\n"
     ]
    }
   ],
   "source": [
    "# TODO - Initialize Parameter Vector w: A vector of shape x_train.shape[1],1 - 5 points\n",
    "w = np.zeros((a.shape[1],1))\n",
    "print(w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Write the hypothesis function - 10 points\n",
    "def hypothesis(a , w):\n",
    "    return sigmoid(a.dot(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Compute y_hat using a and w - 5 points\n",
    "yhat = hypothesis(a,w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Likelihood Function.\n",
    "Write the code to calculate the log likelihood as discussed in the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Write the log likelihood function - 15 points \n",
    "def likelihood(X_tr , Y_tr , w , n):\n",
    "    yhat = hypothesis(X_tr, w) \n",
    "    likelihood = np.sum(Y_tr.dot(np.log(yhat))+(1-Y_tr).dot(np.log(1-yhat)))\n",
    "    return likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-295.2806989185367\n"
     ]
    }
   ],
   "source": [
    "# VERIFY - The value should be equal to -295.2806989185367.\n",
    "print(likelihood(a,y_train,w,a.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Ascent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Write the gradient ascent function - 25 points\n",
    "def Gradient_Ascent(a, y, learning_rate, num_iters):\n",
    "    n = a.shape[0] # Number of training examples.\n",
    "    # TODO - Initialize w. Zeros vector of shape x_train.shape[1],1\n",
    "    w = np.zeros((a.shape[1],1))\n",
    "    # TODO - Reshape y to be a rank 2 matrix.\n",
    "    y = y.reshape((n,1))\n",
    "    # TODO - Initiating list to store values of likelihood after few iterations.\n",
    "    likelihood_values = []\n",
    "    for i in range(num_iters):\n",
    "        yhat = hypothesis(a, w)\n",
    "        error = y - yhat\n",
    "        gradient = np.dot(a.T, error)\n",
    "        # Updating Parameters\n",
    "        w = w + (learning_rate / n) * gradient\n",
    "        if (i % 100) == 0:\n",
    "            likelihood_values.append(likelihood(a,y.T,w,n))\n",
    "        \n",
    "    return w, likelihood_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.19349066]\n",
      " [-0.37337889]\n",
      " [-0.4267242 ]\n",
      " [-0.36908631]\n",
      " [-0.35925814]\n",
      " [-0.16858855]\n",
      " [-0.14184548]\n",
      " [-0.25470797]\n",
      " [-0.36187365]\n",
      " [-0.04257594]\n",
      " [ 0.15288265]\n",
      " [-0.31893724]\n",
      " [ 0.00072844]\n",
      " [-0.28189784]\n",
      " [-0.28616975]\n",
      " [-0.00588282]\n",
      " [ 0.10312685]\n",
      " [ 0.09526653]\n",
      " [-0.08244748]\n",
      " [ 0.11322814]\n",
      " [ 0.19247343]\n",
      " [-0.4421197 ]\n",
      " [-0.46010391]\n",
      " [-0.42639065]\n",
      " [-0.40556242]\n",
      " [-0.33913183]\n",
      " [-0.21470905]\n",
      " [-0.27652263]\n",
      " [-0.41245292]\n",
      " [-0.23329405]\n",
      " [-0.11315285]]\n"
     ]
    }
   ],
   "source": [
    "learning_rate = .001\n",
    "num_iters = 10000\n",
    "w, likelihood_values = Gradient_Ascent(a, y_train, learning_rate, num_iters)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Likelihood v/s Number of Iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run this cell to plot Likelihood v/s Number of Iterations.\n",
    "iters = np.array(range(0,num_iters,100))\n",
    "plt.plot(iters,likelihood_values,'.-',color='green')\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('Likelihood')\n",
    "plt.title(\"Likelihood vs Number of Iterations.\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see the likelihood increasing as number of Iterations increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Write the function to compute predicted values using a and w - 10 points\n",
    "def predict(a, w):\n",
    "    yhat = np.dot(a, w)\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = predict(a,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Write the precision_recall function - 20 points\n",
    "def precision_recall(yhat, y , threshold):\n",
    "    # Write code to compute precision and recall\n",
    "    # Before finding precision or recall, you have to convert yhat into a vector of zeros and ones using threshold.\n",
    "    # Values in yhat > threshold should be equal to 1 and others should be 0.\n",
    "    binY = []\n",
    "    for num in yhat:\n",
    "        if num > threshold:\n",
    "            binY.append(1) \n",
    "        else:\n",
    "            binY.append(0)\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    for i in range(len(binY)):\n",
    "        if binY[i] == 0:\n",
    "            if y[i] == 0:\n",
    "                TN+=1\n",
    "            else:\n",
    "                FN+=1\n",
    "        else:\n",
    "            if y[i] == 0:\n",
    "                FP+=1\n",
    "            else:\n",
    "                TP+=1\n",
    "            \n",
    "    precision = TP/(TP+FP)\n",
    "    recall = TP/(TP+FN)\n",
    "    return precision,recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9760956175298805\n",
      "0.9839357429718876\n"
     ]
    }
   ],
   "source": [
    "precision, recall = precision_recall(yhat, y_train, 0)\n",
    "print(precision)\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98\n"
     ]
    }
   ],
   "source": [
    "# TODO - Write the f_score function - 10 points\n",
    "def f_score(precision, recall):\n",
    "    return 2*(precision*recall)/(precision+recall)\n",
    "\n",
    "print(f_score(precision, recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting Model using Sk Learn Library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Create object of logistic regression model. Pass a large value of C (C = 1/lambda) to make lambda nearly 0. - 5 points\n",
    "logreg = LogisticRegression(C=10000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10000000000)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO - Fit the model - 5 points\n",
    "# Don't use matrix a. Instead, use x_train.\n",
    "logreg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data = 0.916084\n"
     ]
    }
   ],
   "source": [
    "# TODO - Find the predicted values on training set using logreg.predict - 5 points\n",
    "yhat =  logreg.predict(x_test)\n",
    "# TODO - Find the accuracy achieved on training set using logreg.score - 5 points\n",
    "acc = logreg.score(x_test, y_test)\n",
    "\n",
    "print(\"Accuracy on training data = %f\" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  768.64210188  -187.38642505   732.7362076    378.83853141\n",
      "   -496.53365443  1075.95572599   -59.7632269   -433.31936976\n",
      "    245.82989692  -402.18641019  -647.93314173   164.6939966\n",
      "    567.33025605  -918.32374684    20.18567381  -680.36855765\n",
      "    529.69844632  -931.98333976     8.27760823  1286.08584104\n",
      "  -1373.34072659  -610.78089463 -1010.46961458 -1332.8637213\n",
      "     41.88826589   373.84710895   -77.96889328  -298.08570669\n",
      "   -266.0194597   -635.68360172]]\n",
      "[-239.61614392]\n"
     ]
    }
   ],
   "source": [
    "# TODO - Print out all the coefficients - 5 points\n",
    "w = logreg.coef_ \n",
    "intercept = logreg.intercept_\n",
    "# VERIFY - Compare the parameters computed by logreg model and gradient ascent. They should be nearly same.\n",
    "print(w)\n",
    "print(intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Metrics:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76744186 0.98      ]\n",
      "[0.94285714 0.90740741]\n",
      "[0.84615385 0.94230769]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "# TODO - Find Precision, recall and fscore using precision_recall_fscore_support nethod of sklearn - 5 points\n",
    "prec , recal , fscore,_ = precision_recall_fscore_support(y_test, yhat)\n",
    "print(prec)\n",
    "print(recal)\n",
    "print(fscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can compare the values of precision, recall and fscore using the methods you wrote and using sklearn method.\n",
    "To match the values of precision, recall and fscore using both methods, you will have to try different values of threshold in your method."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
